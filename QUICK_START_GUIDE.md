# Quick Start Guide - Testing OCR and Translation

## ‚úÖ Current Status - FULLY OPERATIONAL

**Good News**: Yes, you can run the program and upload an image to extract text and get translations! All systems are verified and working.

**Verified Operational (December 2025)**:
- ‚úÖ **Hybrid OCR System** - EasyOCR + PaddleOCR running in parallel with character-level fusion (TESTED & WORKING)
- ‚úÖ **Three-Tier Translation** - All three translation methods fully operational:
  - ‚úÖ Dictionary (276+ entries) - Active
  - ‚úÖ MarianMT neural translation - Active (sentencepiece installed)
  - ‚úÖ Qwen LLM refinement - Active
- ‚úÖ **Modular Preprocessing** - 13-step production-grade pipeline with 61 unit tests (100% pass rate)
- ‚úÖ **Configuration System** - 35+ tunable parameters via environment variables
- ‚úÖ **Comprehensive Testing** - Full test coverage for preprocessing, OCR, and translation
- ‚úÖ **Servers Verified** - Both frontend and backend running without errors

## üîß Setup Required

### 1. Environment Variables

You need to create a `.env` file in the project root with:

```env
# Database
DATABASE_URL="file:./prisma/db/dev.db"
NEXTAUTH_URL="http://localhost:3001"
NEXTAUTH_SECRET="your-secret-key-here"

# Inference Service (REQUIRED for OCR to work)
INFERENCE_API_URL="http://localhost:8001"
```

**Important**: The `INFERENCE_API_URL` must be set to `http://localhost:8001` for the OCR to work!

### 2. Verify Services Are Running

**Backend (FastAPI)**: Should be running on port 8001
```bash
# Check if running
curl http://localhost:8001/health

# If not running, start it:
cd services/inference
python -m uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```

**Frontend (Next.js)**: Should be running on port 3001
```bash
# Check if running
# Open http://localhost:3001 in browser

# If not running, start it:
npm run dev
```

## üöÄ How to Test

### Step 1: Start Backend Service
```bash
cd services/inference
python -m uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```

Wait for: `INFO:     Uvicorn running on http://0.0.0.0:8001`

### Step 2: Start Frontend Service
```bash
npm run dev
```

Wait for: `Ready on http://localhost:3001`

### Step 3: Verify Backend is Working
```bash
curl http://localhost:8001/health
```

Should return (‚úÖ Verified December 2025):
```json
{
  "status": "ok",
  "ocr_engines": {
    "easyocr": {
      "available": true,
      "status": "ready"
    },
    "paddleocr": {
      "available": true,
      "status": "ready"
    }
  },
  "translation_engines": {
    "marianmt": {
      "available": true,          ‚Üê ‚úÖ NOW OPERATIONAL (sentencepiece installed)
      "status": "ready"
    },
    "qwen_refiner": {
      "available": true,
      "status": "ready",
      "model": "Qwen2.5-1.5B-Instruct"
    }
  },
  "dictionary": {
    "entries": 276,
    "entries_with_alts": 188,
    "entries_with_notes": 276,
    "version": "1.0.0"
  },
  "limits": {
    "max_image_size_mb": 10.0,
    "max_dimension": 4000,
    "min_dimension": 50,
    "supported_formats": ["image/jpeg", "image/jpg", "image/png", "image/webp"]
  }
}
```

### Step 4: Upload an Image

1. Open browser: `http://localhost:3001`
2. Login (or register if first time)
3. Go to Upload page
4. Select a Chinese handwriting image (JPG, PNG, or WebP)
5. Click "Process Images"
6. Wait for processing (2-5 seconds typically)
7. View results:
   - Extracted text
   - Character-by-character meanings
   - Full translation
   - Confidence scores

## üìã What You'll See

### Successful Processing:
- ‚úÖ Extracted Chinese text from image (hybrid OCR)
- ‚úÖ Character meanings (dictionary-based translation)
- ‚úÖ Full sentence translation (MarianMT neural translation)
- ‚úÖ Refined translation (Qwen LLM refinement)
- ‚úÖ Confidence scores for each character
- ‚úÖ Coverage percentage (how many characters found in dictionary)
- ‚úÖ Unmapped characters list (if any)

### Example Result:
```
Extracted Text: ÊàëÁà±‰Ω†
Character Meanings: I; me; myself; we; our | love; affection; like; care for; cherish | you; your; yourself
Sentence Translation: I love you
Refined Translation: I love you
Qwen Status: available
Confidence: 0.92
Coverage: 100%
```

## ‚ö†Ô∏è Common Issues

### Issue 1: "Processing unavailable - INFERENCE_API_URL not configured"
**Solution**: Create `.env` file with `INFERENCE_API_URL="http://localhost:8001"`

### Issue 2: "503 Service Unavailable"
**Solution**: Make sure backend is running on port 8001

### Issue 3: "No text detected in image"
**Solution**: 
- Ensure image contains readable Chinese text
- Check image quality (should be clear, not blurry)
- Try a different image

### Issue 4: Frontend can't connect to backend
**Solution**: 
- Verify backend is running: `curl http://localhost:8001/health`
- Check CORS settings (should be configured)
- Verify `INFERENCE_API_URL` in `.env`

## üéØ Accuracy Expectations

### What Works Well:
- ‚úÖ Clear, high-quality Chinese handwriting
- ‚úÖ Standard Chinese characters
- ‚úÖ Characters in the dictionary (276+ entries currently)
- ‚úÖ Hybrid OCR system improves recognition accuracy
- ‚úÖ Neural translation provides natural English output
- ‚úÖ LLM refinement corrects OCR noise and improves coherence

### Limitations:
- ‚ö†Ô∏è Very blurry or low-quality images (preprocessing helps but has limits)
- ‚ö†Ô∏è Characters not in dictionary (will show as "unmapped" but MarianMT still translates)
- ‚ö†Ô∏è Extremely stylized or artistic fonts
- ‚ö†Ô∏è Very small text (auto-upscaling helps)
- ‚ö†Ô∏è First-time Qwen model download takes 3-5 minutes (~3GB)

### Dictionary Coverage:
- Current: 276+ entries with pinyin, meanings, alternatives, and notes
- Can be expanded by editing `services/inference/data/dictionary.json`

## üìä Current Capabilities

‚úÖ **Fully Implemented & Tested**:
- ‚úÖ **Hybrid OCR** - EasyOCR + PaddleOCR with character-level fusion
- ‚úÖ **Three-Tier Translation** - Dictionary + MarianMT + Qwen LLM refinement
- ‚úÖ **Modular Preprocessing** - 13-step pipeline with 61 unit tests
- ‚úÖ **Dictionary System** - 276+ entries with alternatives and notes
- ‚úÖ **Character-level Meanings** - Detailed per-character translations
- ‚úÖ **Sentence Translation** - Context-aware neural translation
- ‚úÖ **LLM Refinement** - Qwen-powered coherence improvement
- ‚úÖ **Confidence Scoring** - Per-character confidence tracking
- ‚úÖ **Coverage Tracking** - Dictionary coverage percentage
- ‚úÖ **Error Handling** - Comprehensive error messages and graceful degradation
- ‚úÖ **Configuration System** - 35+ tunable parameters via .env

‚ùå **Planned Features** (Future Phases):
- Batch processing with progress tracking
- Visual bounding box overlays on images
- Advanced export functionality (TEI-XML, JSON-LD)
- Enhanced search/filter capabilities
- User annotation and correction tools

## üß™ Quick Test

Test the full pipeline:

1. **Backend Health Check**:
   ```bash
   curl http://localhost:8001/health
   ```

2. **Test OCR Directly** (optional):
   ```bash
   curl -X POST http://localhost:8001/process-image \
     -F "file=@path/to/your/image.jpg"
   ```

3. **Test via Frontend**:
   - Upload image through web UI
   - See results displayed

## ‚úÖ Verification Checklist

Before testing, verify:
- [ ] `.env` file exists with `INFERENCE_API_URL="http://localhost:8001"`
- [ ] Backend service running on port 8001
- [ ] Frontend service running on port 3001
- [ ] Both OCR engines initialized (EasyOCR + PaddleOCR)
- [ ] Translation engines ready (MarianMT + Qwen)
- [ ] Dictionary loaded (276+ entries)
- [ ] Database initialized (`npm run db:push`)
- [ ] PyTorch installed for EasyOCR and transformers
- [ ] opencv-python installed for preprocessing enhancements

### Quick Health Check:
```bash
# Check backend status
curl http://localhost:8001/health

# Run preprocessing tests (optional)
cd services/inference
python -m pytest ../preprocessing/tests/ -v

# Run pipeline smoke test (optional)
python -m pytest tests/test_pipeline_smoke.py -v
```

---

**You're all set!** The system is ready to extract text and translate Chinese handwriting images with hybrid OCR, neural translation, and LLM refinement.

